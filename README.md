```md
# ğŸ¤– LLM Chatbot (FastAPI + Groq + Streamlit)

A clean and minimal end-to-end **LLM-based chatbot** built with **FastAPI** for the backend, **Groq LLM API** for inference, and **Streamlit** for the frontend UI.

This project demonstrates a **production-style architecture** with clear separation between frontend, backend, and LLM logic.

---

## ğŸ“Œ Key Features

- ğŸ”¹ FastAPI backend with clean API design  
- ğŸ”¹ Groq LLM API integration  
- ğŸ”¹ Streamlit-based chat UI  
- ğŸ”¹ Secure API key handling using environment variables  
- ğŸ”¹ Request & response validation with Pydantic  
- ğŸ”¹ Scalable and extensible project structure  

---

## ğŸ§  System Architecture

```

User (Browser)
â†“
Streamlit Frontend
â†“  HTTP POST /chat
FastAPI Backend
â†“
Groq LLM API
â†“
FastAPI Response
â†“
Streamlit UI

```

- Frontend handles **UI only**
- Backend handles **validation, orchestration, and security**
- LLM inference is done by **Groq**

---

## ğŸ“ Project Structure

```

llm_chatbot/
â”‚
â”œâ”€â”€ app/                    # FastAPI Backend
â”‚   â”œâ”€â”€ main.py             # Application entry point
â”‚   â”œâ”€â”€ api/                # API routes
â”‚   â”‚   â””â”€â”€ chat.py
â”‚   â”œâ”€â”€ schemas/            # Request/Response models
â”‚   â”‚   â””â”€â”€ chat.py
â”‚   â”œâ”€â”€ services/           # LLM logic
â”‚   â”‚   â””â”€â”€ groq_client.py
â”‚   â””â”€â”€ core/               # Configuration & settings
â”‚       â””â”€â”€ config.py
â”‚
â”œâ”€â”€ frontend/               # Streamlit Frontend
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ .env                    # Environment variables (not committed)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/llm_chatbot.git
cd llm_chatbot
````

---

### 2ï¸âƒ£ Create a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate      # Linux / Mac
venv\Scripts\activate         # Windows
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Configure Environment Variables

Create a `.env` file in the root directory:

```env
GROQ_API_KEY=your_groq_api_key_here
```

âš ï¸ **Never commit this file to GitHub**

---

## â–¶ï¸ Running the Application

### Start Backend (FastAPI)

```bash
uvicorn app.main:app --reload
```

Backend will be available at:

```
http://127.0.0.1:8000
```

Swagger API Docs:

```
http://127.0.0.1:8000/docs
```

---

### Start Frontend (Streamlit)

Open a new terminal and run:

```bash
streamlit run frontend/app.py
```

Frontend will be available at:

```
http://localhost:8501
```

---

## ğŸ’¬ Example API Usage

### Request

**POST** `/chat`

```json
{
  "message": "Explain transformers in simple words"
}
```

### Response

```json
{
  "reply": "Transformers are models that understand relationships between words..."
}
```

---

## ğŸ›  Tech Stack

* **Python**
* **FastAPI**
* **Groq LLM API**
* **Streamlit**
* **Pydantic**
* **Uvicorn**

---

## ğŸš€ Future Improvements

* Chat history on backend
* Streaming token responses
* RAG (Retrieval-Augmented Generation)
* Authentication & rate limiting
* Dockerization
* Cloud deployment (AWS / GCP / Railway)

---

## ğŸ”’ Security Notes

* API keys are stored in environment variables
* `.env` file is excluded using `.gitignore`
* LLM calls are handled only by the backend

---

## ğŸ“„ License

This project is intended for **learning and demonstration purposes**.

```
